{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9492fa05-6aee-4f34-8dad-6b024fc29943",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Please specify UC config before starting"
    }
   },
   "outputs": [],
   "source": [
    "# utils.py\n",
    "# ============================================================\n",
    "# REQUIRED: UPDATE THESE DEFAULT VALUES FOR YOUR ENVIRONMENT\n",
    "# ============================================================\n",
    "# These values are used when widgets are not enabled, or as \n",
    "# fallback defaults when widget values are empty.\n",
    "# \n",
    "# REPLACE THE VALUES BELOW WITH YOUR OWN:\n",
    "\n",
    "# CATALOG_NAME = \"<your_catalog_name>\"              # TODO: Replace with your Unity Catalog name\n",
    "# SCHEMA_NAME = \"<your_schema_name>\"                # TODO: Replace with your schema name\n",
    "# VOLUME_NAME = \"<your_volume_name>\"                # TODO: Replace with your volume name for file storage\n",
    "# ENDPOINT_NAME = \"<your_external_endpoint_name>\"   # TODO: Replace with your AI Gateway endpoint name\n",
    "\n",
    "## for testing\n",
    "CATALOG_NAME = \"mmt_demos2\"              # TODO: Replace with your Unity Catalog name\n",
    "SCHEMA_NAME = \"ai_driven_drug_discovery\"  # TODO: Replace with your schema name\n",
    "VOLUME_NAME = \"protein_seq\"               # TODO: Replace with your volume name for file storage\n",
    "ENDPOINT_NAME = \"az_openai_gpt4o\"         # TODO: Replace with your AI Gateway endpoint name\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1b81404-8ae8-4694-b565-614d033ac861",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "set up  UC paths configs"
    }
   },
   "outputs": [],
   "source": [
    "def setup_uc_paths(spark: SparkSession = None, \n",
    "                     use_widgets: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Setup Unity Catalog resources and return configuration\n",
    "    \n",
    "    Args:\n",
    "        spark: SparkSession (optional - auto-detected if None)\n",
    "        use_widgets: If True (default), creates widgets for configuration\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with catalog_name, schema_name, volume_name, external_endpoint_name, \n",
    "        volume_location, schema_path, volume_path\n",
    "    \n",
    "    Example:\n",
    "        config = setup_environment()\n",
    "        print(config['catalog_name'])\n",
    "        print(config['volume_location'])\n",
    "    \"\"\"\n",
    "    # Auto-detect spark session if not provided\n",
    "    if spark is None:\n",
    "        spark = SparkSession.getActiveSession()\n",
    "        if spark is None:\n",
    "            raise RuntimeError(\n",
    "                \"No active Spark session found. \"\n",
    "                \"This should not happen in Databricks notebooks.\"\n",
    "            )\n",
    "    \n",
    "    # Setup widgets if requested\n",
    "    if use_widgets:\n",
    "        try:\n",
    "            dbutils.widgets.text(\"catalog_name\", CATALOG_NAME, \"1. Catalog Name\")\n",
    "            dbutils.widgets.text(\"schema_name\", SCHEMA_NAME, \"2. Schema Name\")\n",
    "            dbutils.widgets.text(\"volume_name\", VOLUME_NAME, \"3. Volume Name\")\n",
    "            dbutils.widgets.text(\"external_endpoint_name\", ENDPOINT_NAME, \"4. AI Gateway Endpoint\")\n",
    "        except:\n",
    "            pass  # Widgets may already exist\n",
    "        \n",
    "        # Read values from widgets, fallback to defaults\n",
    "        catalog_name = dbutils.widgets.get(\"catalog_name\") or CATALOG_NAME\n",
    "        schema_name = dbutils.widgets.get(\"schema_name\") or SCHEMA_NAME\n",
    "        volume_name = dbutils.widgets.get(\"volume_name\") or VOLUME_NAME\n",
    "        external_endpoint_name = dbutils.widgets.get(\"external_endpoint_name\") or ENDPOINT_NAME\n",
    "    else:\n",
    "        # Use only hardcoded defaults\n",
    "        catalog_name = CATALOG_NAME\n",
    "        schema_name = SCHEMA_NAME\n",
    "        volume_name = VOLUME_NAME\n",
    "        external_endpoint_name = ENDPOINT_NAME\n",
    "    \n",
    "    # Check for placeholder values\n",
    "    placeholder_configs = []\n",
    "    if catalog_name.startswith(\"<\") and catalog_name.endswith(\">\"):\n",
    "        placeholder_configs.append(\"Catalog Name\")\n",
    "    if schema_name.startswith(\"<\") and schema_name.endswith(\">\"):\n",
    "        placeholder_configs.append(\"Schema Name\")\n",
    "    if volume_name.startswith(\"<\") and volume_name.endswith(\">\"):\n",
    "        placeholder_configs.append(\"Volume Name\")\n",
    "    if external_endpoint_name.startswith(\"<\") and external_endpoint_name.endswith(\">\"):\n",
    "        placeholder_configs.append(\"External Endpoint Name\")\n",
    "    \n",
    "    if placeholder_configs:\n",
    "        if use_widgets:\n",
    "            raise ValueError(\n",
    "                f\"Placeholder values detected. Please fill in the following widget(s) at the top of the notebook:\\n\"\n",
    "                f\"  - {', '.join(placeholder_configs)}\\n\"\n",
    "                f\"Then re-run this cell.\"\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Placeholder values detected. Please update the following value(s) at the top of utils.py:\\n\"\n",
    "                f\"  - {', '.join(placeholder_configs)}\\n\"\n",
    "                f\"Replace the placeholder values (e.g., '<your_catalog_name>') with actual values.\"\n",
    "            )\n",
    "    \n",
    "    # Validate required configuration\n",
    "    missing_configs = []\n",
    "    if not catalog_name:\n",
    "        missing_configs.append(\"Catalog Name\")\n",
    "    if not schema_name:\n",
    "        missing_configs.append(\"Schema Name\")\n",
    "    if not volume_name:\n",
    "        missing_configs.append(\"Volume Name\")\n",
    "    if not external_endpoint_name:\n",
    "        missing_configs.append(\"External Endpoint Name\")\n",
    "    \n",
    "    if missing_configs:\n",
    "        if use_widgets:\n",
    "            raise ValueError(\n",
    "                f\"Please fill in the following widget(s) at the top of the notebook:\\n\"\n",
    "                f\"  - {', '.join(missing_configs)}\\n\"\n",
    "                f\"Then re-run this cell.\"\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Please set the following value(s) at the top of utils.py:\\n\"\n",
    "                f\"  - {', '.join(missing_configs)}\"\n",
    "            )\n",
    "    \n",
    "    # Create UC resources if they don't exist\n",
    "    spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\")\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog_name}.{schema_name}\")\n",
    "    spark.sql(f\"CREATE VOLUME IF NOT EXISTS {catalog_name}.{schema_name}.{volume_name}\")\n",
    "    \n",
    "    # Calculate derived paths\n",
    "    volume_location = f\"/Volumes/{catalog_name}/{schema_name}/{volume_name}\"\n",
    "    schema_path = f\"{catalog_name}.{schema_name}\"\n",
    "    volume_path = f\"{catalog_name}.{schema_name}.{volume_name}\"\n",
    "\n",
    "    uc_config = {\n",
    "        'catalog_name': catalog_name,\n",
    "        'schema_name': schema_name,\n",
    "        'volume_name': volume_name,\n",
    "        'external_endpoint_name': external_endpoint_name,\n",
    "        'volume_location': volume_location,\n",
    "        'schema_path': schema_path,\n",
    "        'volume_path': volume_path\n",
    "    } \n",
    "    \n",
    "    # Print summary\n",
    "    config_source = \" (from widgets)\" if use_widgets else \" (from defaults)\"\n",
    "    print(\"=\"*70)\n",
    "    print(f\"UC Paths Configured{config_source}\")\n",
    "    print(\"=\"*70)\n",
    "    for key, value in uc_config.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return uc_config\n",
    "\n",
    "\n",
    "def remove_widgets() -> None:\n",
    "    \"\"\"\n",
    "    Remove configuration widgets from notebook UI\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dbutils.widgets.removeAll()\n",
    "        print(\"Existing Widgets Removed\")\n",
    "    except:\n",
    "        print(\"No widgets to remove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffea9262-469c-4921-8edc-d8b65598eef2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "test/ example usage"
    }
   },
   "outputs": [],
   "source": [
    "# remove_widgets() \n",
    "# setup_uc_paths(spark=None, use_widgets=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea2e6e9d-4a76-47c8-bda1-3f72b143fc81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0312840a-5f3c-4212-8805-09a8da701315",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ref html to insert image in aibi dashboard"
    }
   },
   "outputs": [],
   "source": [
    "# https://e2-demo-field-eng.cloud.databricks.com/ajax-api/2.0/workspace-files/Users/may.merkletan%40databricks.com/REPOs/ai-driven-drug-discovery/HLS-ai-drug-discovery/imgs/AI-Drug-Discovery-Page2o.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11fe9715-0ace-481e-97fb-c4ec48480872",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_0c235d96-4bc7-4fb5-b118-17fd1dad0124",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "utils",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

# AI-Driven Drug Discovery
How GenAI can help identify promising, under-researched proteins, and uncover their properties for drug discovery

[![Databricks](https://img.shields.io/badge/Databricks-Solution_Accelerator-FF3621?style=for-the-badge&logo=databricks)](https://databricks.com)
[![Unity Catalog](https://img.shields.io/badge/Unity_Catalog-Enabled-00A1C9?style=for-the-badge)](https://docs.databricks.com/en/data-governance/unity-catalog/index.html)
[![Serverless](https://img.shields.io/badge/Serverless-Compute-00C851?style=for-the-badge)](https://docs.databricks.com/en/compute/serverless.html)

<br> 

## Overview  
 
The Life Sciences and Pharmaceutical research and development cycle — which encompasses the discovery, preclinical testing, and early clinical trial phases — is notoriously lengthy, spanning on average ~10-15 years, with a significant portion of drug candidates failing during clinical trials. It is anticipated that the use of Generative AI (GenAI) and Transformer Models will help expedite this process, e.g., by analyzing vast datasets to identify promising drug candidates, predict their efficacy, and optimize molecular structures, leading to faster identification of potential drugs and reducing the time and cost of development ([ref](https://www.mckinsey.com/industries/life-sciences/our-insights/generative-ai-in-the-pharmaceutical-industry-moving-from-hype-to-reality#/)).


This solution accelerator guides you through the development of a [_multi-page_ AIBI Genie](dashboards/README.md) [Dashboard](https://docs.databricks.com/aws/en/dashboards/). The `Protein Classification Data Exploration AI/BI Genie Space with GenAI-backed AI-Queries` is intended to showcase how GenAI can be leveraged to to help focus Downstream Drug Discovery Efforts. 


<!-- The diagram illustrates the flow of processes involved to setup the AIBI Genie space within the [Databricks Intelligent Platform](https://www.databricks.com/resources/demos/tours/horizontal/introducing-databricks-intelligence-platform) and the features utilized (in red).      -->

![architecture sketch](./assets/imgs/process-oreinted_highlevelflowARCH_v0.2.png) 



We will walk through the steps that involve [processing data and writing to Unity Catalog](https://docs.databricks.com/aws/en/data-governance/unity-catalog), [served foundational model endpoints](https://docs.databricks.com/en/generative-ai/external-models.html), registered [AI Functions](https://docs.databricks.com/aws/en/large-language-models/ai-functions), as well as an exported dashboard as a template with query code in the [`/dashboards`](dashboards) folder to expedite the UI development process.
When an AIBI dashboard is [Genie Space](https://docs.databricks.com/aws/en/dashboards/genie-spaces) enabled during publication, users can _"[Ask Genie](https://github.com/databricks-industry-solutions/ai-driven-drug-discovery/blob/mmt_devs/assets/imgs/Dashboard_GenieSpace_enabled.png)"_  as well as [talk to their data](https://github.com/databricks-industry-solutions/ai-driven-drug-discovery/blob/mmt_devs/assets/imgs/AIBI_autogenerated_GenieSpace.png). 

<!-- This solution accelerator guides you through the development of a ["_multi-page_" AI/BI Genie](dashboards/README.md) [Dashboard](https://docs.databricks.com/aws/en/dashboards/) using [processed data written to Unity Catalog](https://docs.databricks.com/aws/en/data-governance/unity-catalog) as well as [served foundational model endpoint](https://docs.databricks.com/en/generative-ai/external-models.html).  

We provide an exported dashboard as a template with query code in the [`/dashboards`](dashboards) folder to expedite the UI development process.

When an AIBI dashboard is [Genie Space](https://docs.databricks.com/aws/en/dashboards/genie-spaces) enabled during publication, users can _"[Ask Genie](https://github.com/databricks-industry-solutions/ai-driven-drug-discovery/blob/mmt_devs/assets/imgs/Dashboard_GenieSpace_enabled.png)"_ , [talk to their data](https://github.com/databricks-industry-solutions/ai-driven-drug-discovery/blob/mmt_devs/assets/imgs/AIBI_autogenerated_GenieSpace.png), and interrogate the datasets.  -->

<!-- Additional information on [resources used](###) are included for reference. -->
   
<br> 
     
---    

### Our example walkthrough highlights the following:    

#### Databricks Features

| Area | Feature | Role in this solution | Why it matters |
|------|---------|-----------------------|----------------|
| **Data & Governance** | **[Lakehouse / Delta](https://docs.databricks.com/en/delta/index.html)** | Stores FASTA raw files and derived protein tables (`enriched_protein`, semantic and research-enriched tables). | Central, scalable store for all protein data and features. |
| **Data & Governance** | **[Unity Catalog](https://docs.databricks.com/en/data-governance/unity-catalog/index.html)** | Governs access to tables and SQL functions (`scientific2simple`, `get_protein_research_info`). | Secure, governed foundation shared by DLT, AI/BI dashboards, and Genie. |
| **Data Engineering** | **[Lakeflow Declarative Pipelines](https://docs.databricks.com/en/delta-live-tables/index.html)** / ("DLT") | Pipeline that ingests and preprocesses FASTA into structured protein tables with quality checks. | Reliable, declarative ETL so downstream AI/BI always sees clean, current data. |
| **Computation** | **[pandas UDFs](https://docs.databricks.com/aws/en/udf/pandas)** | Applies vectorized protein language model inference during the Protein Classification step. | Scales Python/ML inference across large protein datasets. |
| **SQL & AIBI** | **[Databricks SQL](https://docs.databricks.com/en/sql/index.html)** | Runs aggregations and joins for distributions, counts, and high-confidence protein subsets. | Single query layer for both classic analytics and AI-enriched columns. |
| **SQL & AIBI** | **[AI/BI Dashboards](https://docs.databricks.com/en/ai-bi/index.html)** | Presents tiles for summary stats, distributions, organism comparisons, and detailed protein tables. | Visual exploration of protein data for non-coders. |
| **SQL & AIBI** | **Dashboard parameters & visuals** | Filters (`Organism_SimpleTerm`, `score thresholds`, `ProteinType`) and charts/tables bound to SQL. | Interactive “what-if” exploration within the dashboard. |
| **AI Integration** | **[`ai_query()`](https://docs.databricks.com/aws/en/sql/language-manual/functions/ai_query)** / **[AI functions](https://docs.databricks.com/aws/en/large-language-models/ai-functions)** | SQL entry point to LLMs, used inside `scientific2simple` and `get_protein_research_info`. | Directly augments tables with AI-generated fields from within SQL. |
| **AI Integration** | **[Databricks hosted foundational LLMs: FMAPI](https://docs.databricks.com/aws/en/machine-learning/model-serving/score-foundation-models)** (e.g., Llama, Claude, OpenAI, etc.)| Power `scientific2simple()` to convert scientific organism/protein text into layman terms. | Creates the semantic layer (`Organism_SimpleTerm`, `SimpleTerms`). |
| **AI Integration** | **[External models](https://docs.databricks.com/en/generative-ai/external-models.html)** (e.g., AzureOpenaI_GPT4o)| Power `get_protein_research_info()` to attach recent/under‑researched context. | Turns rows into actionable research leads. |
| **AI Integration** | **[UC Functions](https://docs.databricks.com/aws/en/sql/language-manual/sql-ref-syntax-ddl-create-sql-function)** (SQL & Python) | Registers `scientific2simple()` and `get_protein_research_info()` as reusable SQL functions. | Standardizes and reuses AI logic across queries, dashboards, and Genie. |
| **Exploration UX** | **EDA & ad-hoc queries** | Parameterized tiles and queries for distributions, diversity, and high‑confidence subsets. | Guided and custom exploration on the same governed data. |
| **Exploration UX** | **Precomputed enrichment** | Stores AI-enriched research info in UC tables consumed by the dashboard. | Fast interaction without repeated external model calls. |
| **Conversational Analytics** | **[Genie Space](https://docs.databricks.com/en/genie/index.html)** | Natural-language interface over the same UC tables and functions. | Lets users explore proteins and insights via chat instead of SQL. |
| **Operationalization** | **AI semantic layer** | `Organism_SimpleTerm` and `SimpleTerms` reused by dashboards and Genie. | Bridges scientific jargon and business-friendly search/filter terms. |


---   

## Getting Started

Clone this repository to your Databricks Workspace.    

You will find the set of notebooks referenced above within the [`/notebooks`](notebooks) folder and the dashboard json as well as related files within [`/dashboards`](dashboards).      

Note: Dashboard Unity Catalog-tables will need to be re-referenced after they are being generated via the notebooks. 

Please refer to [`README.md` within `./notebooks`](notebooks/README.md) section for more details about each notebook and how to run them and refer to the [`README.md` within `./dashboards`](dashboards/README.md) for guidance on dashboard configurations.

<br>

---     

## Contributing

**We welcome contributions!**  

- Please review [CONTRIBUTING.md](CONTRIBUTING.md) for more details and guidance prior to contributing.
- **`git clone`** this project locally
- If you are working on assets that require CICD and trigger git actions or rely on Databricks Asset Bundles, utilize the [Databricks Asset Bundles (DABs) documentation](https://docs.databricks.com/aws/en/dev-tools/bundles/) and the [Databricks CLI](https://docs.databricks.com/aws/en/dev-tools/cli/) to test your changes against a Databricks workspace of your choice
- Contribute to repositories with pull requests (PRs), ensuring that you always have a second-party review from a capable teammate

<!-- Please refer to [REPO_structure.md](REPO_structure.md) and [CONTRIBUTING.md](CONTRIBUTING.md) for more details and guidance.     -->

---   

## How to get help
Databricks support doesn't cover this content. For questions or bugs, please open a GitHub issue and the team will help on a best effort basis.   

---   

## Licenses

&copy; 2026 Databricks, Inc. All rights reserved. The source in this project is provided subject to the Databricks License [https://databricks.com/db-license-source]. All included or referenced third party libraries are subject to the licenses set forth below.

| Package | License | Copyright |
|---------|---------|-----------|
| [biopython](https://github.com/biopython/biopython) | [Biopython License Agreement (dual licensed with BSD 3-Clause)](https://github.com/biopython/biopython/blob/master/LICENSE.rst) | Copyright (c) 1999-2024, The Biopython Contributors |
| [databricks-sdk](https://github.com/databricks/databricks-sdk-py) | [Apache License 2.0](https://github.com/databricks/databricks-sdk-py/blob/main/LICENSE) | Copyright 2023-present, Databricks, Inc. |
| [pandas](https://github.com/pandas-dev/pandas) | [BSD 3-Clause License](https://github.com/pandas-dev/pandas/blob/main/LICENSE) | Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team; Copyright (c) 2011-present, Open source contributors |
| [pyspark](https://github.com/apache/spark) | [Apache License 2.0](https://github.com/apache/spark/blob/master/LICENSE) | Copyright 2014-present, The Apache Software Foundation |
| [Rostlab/prot_bert_bfd_membrane](https://huggingface.co/Rostlab/prot_bert_bfd_membrane) | [Academic Free License v3.0 (Model Weights)](https://opensource.org/license/afl-3-0-php) | Copyright 2020, Elnaggar et al. (Rostlab, TUM) |
| [torch](https://github.com/pytorch/pytorch) | [BSD 3-Clause License (Modified BSD)](https://github.com/pytorch/pytorch/blob/main/LICENSE) | Copyright (c) 2016-present, Facebook, Inc. and contributors |
| [transformers](https://github.com/huggingface/transformers) | [Apache License 2.0](https://github.com/huggingface/transformers/blob/main/LICENSE) | Copyright 2018-present, The Hugging Face team |
| [UniProt (uniprot_sprot.fasta.gz)](https://www.uniprot.org/help/downloads) | [Creative Commons Attribution 4.0 (CC BY 4.0)](https://www.uniprot.org/help/license) | Copyright 2002-present, The UniProt Consortium |


<!-- | Package | License | Copyright |
|---------|---------|-----------|
| | | | -->

---   
